{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daAGCP-Zk9nA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "141797c7-567c-4c71-db71-041186c0d824"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of duplicates: 0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import csv\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def find_duplicates(urls):\n",
        "    # Tokenize URLs\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    url_vectors = vectorizer.fit_transform(urls)\n",
        "\n",
        "    # Calculate cosine similarity between URL vectors\n",
        "    similarity_matrix = cosine_similarity(url_vectors)\n",
        "\n",
        "    # Find duplicates\n",
        "    duplicates = []\n",
        "    for i in range(len(urls)):\n",
        "        for j in range(i + 1, len(urls)):\n",
        "            similarity_score = similarity_matrix[i][j]\n",
        "            if similarity_score > 0.9:  # Adjust the threshold as needed\n",
        "                duplicates.append((urls[i], urls[j]))\n",
        "\n",
        "    return duplicates\n",
        "\n",
        "# Add your URLs\n",
        "urls = [\n",
        "    \"RIVER FALLS\tREM WISCONSIN III INC GLENMEADOW\",\n",
        "    \"GREEN BAY\tMCCORMICK ASSISTED LIVING\",\n",
        "    \"Brookfield\tBrookdale Brookfield Capitol Dr\",\n",
        "    \"STOUGHTON\tLINCOLN AFH\",\n",
        "    \"MILWAUKEE\tANGEL HEARTS ADULT CARE CENTER\",\n",
        "    \"SPOONER\tOAK VIEW ADULT FAMILY HOME 4\",\n",
        "    \"ONALASKA\tSPRINGBROOK COMMUNITY ASSISTED LIVING INC\",\n",
        "    \"GREEN BAY\tREM ONTARIO\",\n",
        "    \"APPLETON\tHELENS HOUSE DARBOY\",\n",
        "    \"SOUTH MILWAUKEE\tCHI FRANCISCAN VILLA\",\n",
        "    \"VIROQUA\tCAMPBELL FAMILY HOMES FAIRVIEW DR\",\n",
        "    \"STOUGHTON\tMILESTONE SENIOR LIVING STOUGHTON\",\n",
        "    \"SHEBOYGAN\tVISTA CARE NORTH 49TH STREET AFH\",\n",
        "    \"KENOSHA\tSERENITY HOME HEALTH CARE LLC\",\n",
        "    \"WEST ALLIS\tLIBRARY SQUARE\",\n",
        "    \"MIDDLETON\tPINELANE ADULT FAMILY HOME\",\n",
        "    \"BEAVER DAM\tTROSTEN HAUS\",\n",
        "    \"BOSCOBEL\tBONNIES ADULT FAMILY HOME\",\n",
        "    \"AMERY\tAMERY ASSTD LIV -RIVER BEND\",\n",
        "    \"CHIPPEWA FALLS\tGUDMANSON AFH\",\n",
        "    \"BELOIT\tAUTUMN LAKE HEALTHCARE AT BELOIT\",\n",
        "    \"WAUWATOSA\tST CAMILLUS HEALTH CENTER\",\n",
        "    \"MANITOWOC\tMANITOWOC HEALTHCARE CENTER\",\n",
        "    \"MILWAUKEE\tST ANN REST HOME\",\n",
        "    \"THORP\tK&D COUNTRY LIVING HOME\",\n",
        "    \"MILWAUKEE\tSMITHS LOVING HANDS LLC\",\n",
        "    \"MILWAUKEE\tFRIENDS OF FAMILY ADULT HOME\",\n",
        "    \"MILWAUKEE\tMERCY HEALTH SERVICES\",\n",
        "    \"BERLIN\tHEARTSONG\",\n",
        "    \"TOMAH\tANTONY ADULT FAMILY HOME\",\n",
        "    \"SOUTH MILWAUKEE\tCOMMUNITY ADULT FAMILY HOME LLC\",\n",
        "    \"APPLETON\tRESCARE RANDYS LN\",\n",
        "    \"MADISON\tTRINITY ADULT FAMILY HOME LLC\",\n",
        "    \"WEST SALEM\tSALEM TERRACE\",\n",
        "    \"GREEN BAY\tGRANCARE NURSING CENTER\",\n",
        "    \"EAU CLAIRE\tNORTHWEST PATHWAYS TO INDEPENDENCE 14-CALUMET\",\n",
        "    \"ARENA\tDALOGASA GARDENS\",\n",
        "    \"WHITEHALL\tTREMPEALEAU COUNTY HEALTH CARE CENTER-IMD\",\n",
        "    \"MONROE\tGREENCO HOUSE V\",\n",
        "    \"MILWAUKEE\tFAVOR CHRISTIAN HOME LLC\",\n",
        "    \"MILWAUKEE\tMARIA LINDEN 72 LLC\",\n",
        "    \"EAU CLAIRE\tGCBK GROUP HOME INC\",\n",
        "    \"MADISON\t4544 CWC\",\n",
        "    \"MILWAUKEE\tNEW LIFE NEW LOVE ADULT FAMILY HOME LLC\",\n",
        "    \"BRILLION\tNATIONAL HOUSE\",\n",
        "    \"MILWAUKEE\tREM WISCONSIN II INC WILLOW\",\n",
        "    \"BERLIN\tEVERGREEN HOME OF BERLIN\",\n",
        "    \"WHITEWATER\tHOUSE OF CARE\",\n",
        "    \"WHITEWATER\tKINDRED HEARTS FAMILY HOME\",\n",
        "    \"KEWASKUM\tKETTLE MORAINE GARDENS RCAC\",\n",
        "    \"FORT ATKINSON\tWILLOW WAY ADULT FAMILY HOME\",\n",
        "    \"GREEN BAY\tWINDSOR HOME\",\n",
        "    \"RACINE\tA LOVING CARE GROUP HOMES II LLC\",\n",
        "    \"HUDSON\tGRATUS AT BLUE JAY 719 B\",\n",
        "    \"NEW RICHMOND\tCHRIS HOMES B LLC\",\n",
        "    \"CHILTON\tCALUMET COUNTY HOSPICE AGENCY\",\n",
        "    \"STEVENS POINT\tADULT DAY CENTER OF PORTAGE COUNTY\",\n",
        "    \"MADISON\tABLE HOME LLC\",\n",
        "    \"RICE LAKE\tDAYBREAK I\",\n",
        "    \"GREEN BAY\tALZHEIMERS ADULT DAY PROGRAM\",\n",
        "    \"RACINE\tVISIONS OF LIFE LLC\",\n",
        "    \"MILWAUKEE\tMORGANS WAY WEST\",\n",
        "    \"FALL CREEK\tPALMER PLACE FALL CREEK\",\n",
        "    \"MADISON\tEMMANUEL FAMILY HOME\",\n",
        "    \"SHEBOYGAN\tMORNINGSIDE HEALTH SERVICES\",\n",
        "    \"COLBY\tAUBERG ACRES\",\n",
        "    \"WAUWATOSA\tPOSITIVE OUTLOOK\",\n",
        "    \"SOUTH MILWAUKEE\tOAKWOOD HOUSE OF WAUKESHA CORP MARION\",\n",
        "    \"DODGEVILLE\tUPLAND HILLS HOSPICE\",\n",
        "    \"WAUWATOSA\tVITAS HEALTHCARE CORP MIDWEST\",\n",
        "    \"EAU CLAIRE\tNORTHWEST PATHWAYS TO INDEPENDENCE INC 6\",\n",
        "    \"WATERFORD\tPERSONALLY YOURS ELDER CARE B\",\n",
        "    \"MOUNT PLEASANT\tBEACON OF HOPE ADULT FAMILY HOME\",\n",
        "    \"MADISON\tREM INC TWIN PINES\",\n",
        "    \"WEST ALLIS\tKINDRED HOSPICE\",\n",
        "    \"OSHKOSH\tCLARITY CARE VINLAND II HOUSE\",\n",
        "    \"MILWAUKEE\tREADY CARE AFH II\",\n",
        "    \"WEST BEND\tSTEPPING STONE GROUP HOME LLC\",\n",
        "    \"MILWAUKEE\tDIAMOND ADULT FAMILY HOME\",\n",
        "    \"JUNEAU\tCLEARVIEW BEHAVIORAL HEALTH II\",\n",
        "    \"ELLSWORTH\tELLSWORTH HEALTH SERVICES\",\n",
        "    \"RIPON\tDIVERSE OPTIONS INC COUNTRY ACRES\",\n",
        "    \"GREEN BAY\tREBEKAH HAVEN\",\n",
        "    \"APPLETON\tKAYLEE LANE ADULT FAMILY HOME\",\n",
        "    \"RACINE\tMANHATTAN HOME ADULT FAMILY GROUP HOME\",\n",
        "    \"WHITEHALL\tGUNDERSEN TRI-COUNTY CARE CENTER\",\n",
        "    \"PIGEON FALLS\tRIVER WAY NORTH ADULT FAMILY HOME\",\n",
        "    \"HILLSBORO\tMILESTONE SENIOR LIVING HILLSBORO\",\n",
        "    \"SUN PRAIRIE\tSTURDY OAKS\",\n",
        "    \"GRAFTON\tVILLAGE POINTE COMMONS THE PINNACLE\",\n",
        "    \"KENOSHA\tCROSSROADS CARE CENTER OF KENOSHA\",\n",
        "    \"FALL RIVER\tMEADOWS OF FALL RIVER\",\n",
        "    \"COLBY\tCOLBY RETIREMENT COMMUNITY\",\n",
        "    \"MILWAUKEE\tMONARCH RESIDENTIAL HOME\",\n",
        "    \"FOND DU LAC\tHARBOR HAVEN HEALTH AND REHABILITATION\",\n",
        "    \"MILWAUKEE\tJEWISH HOME & CARE CENTER ADULT DAY CENTER\",\n",
        "    \"SUAMICO\tEAGLE VIEW AFH\",\n",
        "    \"RACINE\tLILAC HOME\",\n",
        "    \"HARTFORD\tHOME CARE SOLUTIONS AT HOME\"\n",
        "]\n",
        "\n",
        "# Find duplicates\n",
        "duplicate_pairs = find_duplicates(urls)\n",
        "\n",
        "# Count duplicates\n",
        "duplicate_count = len(duplicate_pairs)\n",
        "\n",
        "# Store duplicates in a new CSV file\n",
        "with open('duplicates.csv', 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['URL 1', 'URL 2'])  # Write header\n",
        "    writer.writerows(duplicate_pairs)\n",
        "\n",
        "# Print count of duplicates\n",
        "print(f\"Number of duplicates: {duplicate_count}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from nltk import ngrams\n",
        "from collections import Counter\n",
        "\n",
        "def jaccard_similarity(set1, set2):\n",
        "    intersection = set1.intersection(set2)\n",
        "    union = set1.union(set2)\n",
        "    return len(intersection) / len(union)\n",
        "\n",
        "def find_duplicates_jaccard(rows):\n",
        "    duplicates = []\n",
        "    for i in range(len(rows)):\n",
        "        for j in range(i + 1, len(rows)):\n",
        "            set1 = set(ngrams(rows[i], n=2))\n",
        "            set2 = set(ngrams(rows[j], n=2))\n",
        "            similarity_score = jaccard_similarity(set1, set2)\n",
        "            if similarity_score == 1.0:  # Adjust the threshold as needed\n",
        "                duplicates.append((rows[i], rows[j], similarity_score))\n",
        "    return duplicates\n",
        "\n",
        "def find_duplicates_cosine(rows):\n",
        "    urls = [\" \".join(row) for row in rows]\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    url_vectors = vectorizer.fit_transform(urls)\n",
        "    similarity_matrix = cosine_similarity(url_vectors)\n",
        "\n",
        "    duplicates = []\n",
        "    for i in range(len(urls)):\n",
        "        for j in range(i + 1, len(urls)):\n",
        "            similarity_score = similarity_matrix[i][j]\n",
        "            if similarity_score == 1.0:  # Adjust the threshold as needed\n",
        "                duplicates.append((rows[i], rows[j], similarity_score))\n",
        "    return duplicates\n",
        "\n",
        "# Load dataset from CSV\n",
        "dataset_path = '/content/wisconsin - wisconsin (1).csv'\n",
        "rows = []\n",
        "with open(dataset_path, 'r') as file:\n",
        "    reader = csv.reader(file)\n",
        "    next(reader)  # Skip header row\n",
        "    for row in reader:\n",
        "        rows.append(row)\n",
        "\n",
        "# Find duplicates using Jaccard similarity\n",
        "duplicate_pairs_jaccard = find_duplicates_jaccard(rows)\n",
        "\n",
        "# Find duplicates using Cosine similarity\n",
        "duplicate_pairs_cosine = find_duplicates_cosine(rows)\n",
        "\n",
        "# Write Jaccard duplicates to a new CSV file\n",
        "output_path_jaccard = '/content/duplicates_jaccard.csv'\n",
        "with open(output_path_jaccard, 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['Row 1', 'Row 2', 'Similarity Score'])\n",
        "    for pair in duplicate_pairs_jaccard:\n",
        "        writer.writerow([pair[0], pair[1], pair[2]])\n",
        "\n",
        "# Write Cosine duplicates to a new CSV file\n",
        "output_path_cosine = '/content/duplicates_cosine.csv'\n",
        "with open(output_path_cosine, 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['Row 1', 'Row 2', 'Similarity Score'])\n",
        "    for pair in duplicate_pairs_cosine:\n",
        "        writer.writerow([pair[0], pair[1], pair[2]])\n",
        "\n",
        "# Count duplicates\n",
        "duplicate_count_jaccard = len(duplicate_pairs_jaccard)\n",
        "duplicate_count_cosine = len(duplicate_pairs_cosine)\n",
        "\n",
        "# Print count of duplicates\n",
        "print(f\"Number of duplicates (Jaccard similarity): {duplicate_count_jaccard}\")\n",
        "print(f\"Number of duplicates (Cosine similarity): {duplicate_count_cosine}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "413SQiJe__K8",
        "outputId": "fbaf93b1-06a4-4ff7-daff-538c343d3779"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of duplicates (Jaccard similarity): 14\n",
            "Number of duplicates (Cosine similarity): 66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from nltk import ngrams\n",
        "\n",
        "def jaccard_similarity(set1, set2):\n",
        "    intersection = set1.intersection(set2)\n",
        "    union = set1.union(set2)\n",
        "    return len(intersection) / len(union)\n",
        "\n",
        "def find_duplicates(rows):\n",
        "    duplicates = []\n",
        "    for i in range(len(rows)):\n",
        "        for j in range(i + 1, len(rows)):\n",
        "            set1 = set(ngrams(rows[i], n=2))\n",
        "            set2 = set(ngrams(rows[j], n=2))\n",
        "            similarity_score = jaccard_similarity(set1, set2)\n",
        "            if similarity_score >= 0.9:  # Adjust the threshold as needed\n",
        "                duplicates.append((rows[i], rows[j], similarity_score))\n",
        "    return duplicates\n",
        "\n",
        "# Load dataset from CSV\n",
        "dataset_path = '/content/wisconsin - wisconsin (1).csv'\n",
        "rows = []\n",
        "with open(dataset_path, 'r') as file:\n",
        "    reader = csv.reader(file)\n",
        "    next(reader)  # Skip header row\n",
        "    for row in reader:\n",
        "        rows.append(row)\n",
        "\n",
        "# Find duplicates using Jaccard similarity\n",
        "duplicate_pairs = find_duplicates(rows)\n",
        "\n",
        "# Write duplicates to a new CSV file\n",
        "output_path = '/content/duplicates_jaccard.csv'\n",
        "with open(output_path, 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['Row 1', 'Row 2', 'Similarity Score'])\n",
        "    for pair in duplicate_pairs:\n",
        "        writer.writerow([pair[0], pair[1], pair[2]])\n",
        "\n",
        "# Count duplicates\n",
        "duplicate_count = len(duplicate_pairs)\n",
        "\n",
        "# Print count of duplicates\n",
        "print(f\"Number of duplicates: {duplicate_count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ax8t_LchKVU6",
        "outputId": "b01d0eb5-d648-4842-a647-c6311121e547"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of duplicates: 14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from nltk import ngrams\n",
        "\n",
        "def jaccard_similarity(set1, set2):\n",
        "    intersection = set1.intersection(set2)\n",
        "    union = set1.union(set2)\n",
        "    return len(intersection) / len(union)\n",
        "\n",
        "def find_duplicates(rows):\n",
        "    duplicates = []\n",
        "    for i in range(len(rows)):\n",
        "        for j in range(i + 1, len(rows)):\n",
        "            set1 = set(ngrams(rows[i], n=2))\n",
        "            set2 = set(ngrams(rows[j], n=2))\n",
        "            similarity_score = jaccard_similarity(set1, set2)\n",
        "            if similarity_score >= 0.5:  # Adjust the threshold as needed\n",
        "                duplicates.append((rows[i], rows[j], similarity_score))\n",
        "    return duplicates\n",
        "\n",
        "# Load dataset from CSV\n",
        "dataset_path = '/content/wisconsin - wisconsin (1).csv'\n",
        "rows = []\n",
        "with open(dataset_path, 'r') as file:\n",
        "    reader = csv.reader(file)\n",
        "    next(reader)  # Skip header row\n",
        "    for row in reader:\n",
        "        rows.append(row)\n",
        "\n",
        "# Find duplicates using Jaccard similarity\n",
        "duplicate_pairs = find_duplicates(rows)\n",
        "\n",
        "# Write duplicates to a new CSV file\n",
        "output_path = '/content/duplicates_jaccard.csv'\n",
        "with open(output_path, 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['Row 1', 'Row 2', 'Similarity Score'])\n",
        "    for pair in duplicate_pairs:\n",
        "        writer.writerow([pair[0], pair[1], pair[2]])\n",
        "\n",
        "# Count duplicates\n",
        "duplicate_count = len(duplicate_pairs)\n",
        "\n",
        "# Print count of duplicates\n",
        "print(f\"Number of duplicates: {duplicate_count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4WRuDg_Kvji",
        "outputId": "a16125b0-02eb-4c7c-9f1b-00cf5131e313"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of duplicates: 14\n"
          ]
        }
      ]
    }
  ]
}