{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncWNEPjdLmr_",
        "outputId": "4f2faaf3-0c7c-458f-c0dc-315729e9331b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of duplicates: 1\n",
            "---\n",
            "URL 1: green BAY\tMCCORMICK ASSISTED LIVING\n",
            "URL 2: MCCORMICK ASSISTED LIVING\n",
            "Similarity Score: 1.0\n"
          ]
        }
      ],
      "source": [
        "from nltk import ngrams\n",
        "\n",
        "def jaccard_similarity(set1, set2):\n",
        "    intersection = set1.intersection(set2)\n",
        "    union = set1.union(set2)\n",
        "    return len(intersection) / len(union) if len(union) != 0 else 0\n",
        "\n",
        "def find_duplicates(urls, threshold):\n",
        "    duplicates = []\n",
        "    seen = []\n",
        "\n",
        "    for url in urls:\n",
        "        tokens = url.split('\\t')\n",
        "        if tokens:\n",
        "            sentence = tokens[-1].strip()\n",
        "            if sentence:\n",
        "                sentence_set = set(ngrams(sentence.lower().split(), 3))  # Generate trigrams for the sentence\n",
        "\n",
        "                is_duplicate = False\n",
        "                for seen_sentence, seen_set in seen:\n",
        "                    similarity = jaccard_similarity(sentence_set, seen_set)\n",
        "                    if similarity >= threshold:\n",
        "                        duplicates.append((url, seen_sentence, similarity))\n",
        "                        is_duplicate = True\n",
        "                        break\n",
        "\n",
        "                if not is_duplicate:\n",
        "                    seen.append((sentence, sentence_set))\n",
        "\n",
        "    return duplicates\n",
        "\n",
        "# Example list of URLs\n",
        "urls = [\n",
        "    \"RIVER FALLS\\tREM WISCONSIN III INC GLENMEADOW\",\n",
        "    \"GREEN BAY\\tMCCORMICK ASSISTED LIVING\",\n",
        "    \"green BAY\\tMCCORMICK ASSISTED LIVING\",\n",
        "    \"green BAY\\tMCCORMICK ASSISTED LIVINGIII\",\n",
        "    \"Brookfield\\tBrookdale Brookfield Capitol Dr\",\n",
        "    \"STOUGHTON\\tLINCOLN AFH\",\n",
        "    \"MILWAUKEE\\tANGEL HEARTS ADULT CARE CENTER\",\n",
        "    \"SPOONER\\tOAK VIEW ADULT FAMILY HOME 4\",\n",
        "    \"ONALASKA\\tSPRINGBROOK COMMUNITY ASSISTED LIVING INC\",\n",
        "    \"GREEN BAY\\tREM ONTARIO\",\n",
        "    \"APPLETON\\tHELENS HOUSE DARBOY\",\n",
        "    \"SOUTH MILWAUKEE\\tCHI FRANCISCAN VILLA\",\n",
        "    \"VIROQUA\\tCAMPBELL FAMILY HOMES FAIRVIEW DR\",\n",
        "    \"STOUGHTON\\tMILESTONE SENIOR LIVING STOUGHTON\",\n",
        "    \"SHEBOYGAN\\tVISTA CARE NORTH 49TH STREET AFH\",\n",
        "    \"KENOSHA\\tSERENITY HOME HEALTH CARE LLC\"\n",
        "]\n",
        "\n",
        "threshold = 0.7  # Adjust the threshold as needed\n",
        "\n",
        "duplicates = find_duplicates(urls, threshold)\n",
        "\n",
        "print(\"Number of duplicates:\", len(duplicates))\n",
        "for url, duplicate, similarity in duplicates:\n",
        "    print(\"---\")\n",
        "    print(\"URL 1:\", url)\n",
        "    print(\"URL 2:\", duplicate)\n",
        "    print(\"Similarity Score:\", similarity)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import ngrams\n",
        "\n",
        "def jaccard_similarity(set1, set2):\n",
        "    intersection = set1.intersection(set2)\n",
        "    union = set1.union(set2)\n",
        "    return len(intersection) / len(union) if len(union) != 0 else 0\n",
        "\n",
        "def find_duplicates(urls, threshold):\n",
        "    duplicates = []\n",
        "\n",
        "    for i in range(len(urls)):\n",
        "        url1 = urls[i]\n",
        "        tokens1 = url1.split('\\t')\n",
        "        if tokens1:\n",
        "            sentence1 = tokens1[-1].strip()\n",
        "            if sentence1:\n",
        "                sentence_set1 = set(ngrams(sentence1.lower().split(), 3))\n",
        "\n",
        "                for j in range(i + 1, len(urls)):\n",
        "                    url2 = urls[j]\n",
        "                    tokens2 = url2.split('\\t')\n",
        "                    if tokens2:\n",
        "                        sentence2 = tokens2[-1].strip()\n",
        "                        if sentence2:\n",
        "                            sentence_set2 = set(ngrams(sentence2.lower().split(), 3))\n",
        "\n",
        "                            similarity = jaccard_similarity(sentence_set1, sentence_set2)\n",
        "                            if similarity >= threshold:\n",
        "                                duplicates.append((url1, url2, similarity))\n",
        "\n",
        "    return duplicates\n",
        "\n",
        "# Example list of URLs\n",
        "urls = [\n",
        "    \"RIVER FALLS\\tREM WISCONSIN III INC GLENMEADOW\",\n",
        "    \"GREEN BAY\\tMCCORMICK ASSISTED LIVING\",\n",
        "    \"green BAY\\tMCCORMICK ASSISTED LIVING\",\n",
        "    \"GREEN BAY\\tMCCORMICK ASSISTED IVINGIIIII\",\n",
        "    \"Brookfield\\tBrookdale Brookfield Capitol Dr\",\n",
        "    \"STOUGHTON\\tLINCOLN AFH\",\n",
        "    \"MILWAUKEE\\tANGEL HEARTS ADULT CARE CENTER\",\n",
        "    \"SPOONER\\tOAK VIEW ADULT FAMILY HOME 4\",\n",
        "    \"ONALASKA\\tSPRINGBROOK COMMUNITY ASSISTED LIVING INC\",\n",
        "    \"GREEN BAY\\tREM ONTARIO\",\n",
        "    \"APPLETON\\tHELENS HOUSE DARBOY\",\n",
        "    \"SOUTH MILWAUKEE\\tCHI FRANCISCAN VILLA\",\n",
        "    \"VIROQUA\\tCAMPBELL FAMILY HOMES FAIRVIEW DR\",\n",
        "    \"STOUGHTON\\tMILESTONE SENIOR LIVING STOUGHTON\",\n",
        "    \"SHEBOYGAN\\tVISTA CARE NORTH 49TH STREET AFH\",\n",
        "    \"KENOSHA\\tSERENITY HOME HEALTH CARE LLC\"\n",
        "]\n",
        "\n",
        "threshold = 0.6  # Adjust the threshold as needed\n",
        "\n",
        "duplicates = find_duplicates(urls, threshold)\n",
        "\n",
        "print(\"Number of duplicates:\", len(duplicates))\n",
        "for url1, url2, similarity in duplicates:\n",
        "    print(\"---\")\n",
        "    print(\"URL 1:\", url1)\n",
        "    print(\"URL 2:\", url2)\n",
        "    print(\"Similarity Score:\", similarity)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZFIKu8UOqt9",
        "outputId": "3c5a5687-b1d1-4a44-ee22-44ab10ad96da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of duplicates: 1\n",
            "---\n",
            "URL 1: GREEN BAY\tMCCORMICK ASSISTED LIVING\n",
            "URL 2: green BAY\tMCCORMICK ASSISTED LIVING\n",
            "Similarity Score: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from difflib import SequenceMatcher\n",
        "\n",
        "def find_duplicates(urls, threshold):\n",
        "    duplicates = []\n",
        "\n",
        "    for i in range(len(urls)):\n",
        "        url1 = urls[i]\n",
        "        tokens1 = url1.split('\\t')\n",
        "        if tokens1:\n",
        "            sentence1 = tokens1[-1].strip()\n",
        "            if sentence1:\n",
        "                for j in range(i + 1, len(urls)):\n",
        "                    url2 = urls[j]\n",
        "                    tokens2 = url2.split('\\t')\n",
        "                    if tokens2:\n",
        "                        sentence2 = tokens2[-1].strip()\n",
        "                        if sentence2:\n",
        "                            similarity = SequenceMatcher(None, sentence1.lower(), sentence2.lower()).ratio()\n",
        "                            if similarity >= threshold:\n",
        "                                duplicates.append((url1, url2, similarity))\n",
        "\n",
        "    return duplicates\n",
        "\n",
        "# Example list of URLs\n",
        "urls = [\n",
        "    \"RIVER FALLS\\tREM WISCONSIN III INC GLENMEADOW\",\n",
        "    \"GREEN BAY\\tMCCORMICK ASSISTED LIVING\",\n",
        "    \"green BAY\\tMCCORMICK ASSISTED LIVING\",\n",
        "    \"GREEN BAY\\tMCCORMICK ASSISTED LIVINGIIIII\"\n",
        "]\n",
        "\n",
        "threshold = 0.9  # Adjust the threshold as needed\n",
        "\n",
        "duplicates = find_duplicates(urls, threshold)\n",
        "\n",
        "print(\"Number of duplicates:\", len(duplicates))\n",
        "for url1, url2, similarity in duplicates:\n",
        "    print(\"---\")\n",
        "    print(\"URL 1:\", url1)\n",
        "    print(\"URL 2:\", url2)\n",
        "    print(\"Similarity Score:\", similarity)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BB50cMrdSXEe",
        "outputId": "80432d3b-398e-4efd-fc4d-1ea8fae7929f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of duplicates: 3\n",
            "---\n",
            "URL 1: GREEN BAY\tMCCORMICK ASSISTED LIVING\n",
            "URL 2: green BAY\tMCCORMICK ASSISTED LIVING\n",
            "Similarity Score: 1.0\n",
            "---\n",
            "URL 1: GREEN BAY\tMCCORMICK ASSISTED LIVING\n",
            "URL 2: GREEN BAY\tMCCORMICK ASSISTED LIVINGIIIII\n",
            "Similarity Score: 0.9090909090909091\n",
            "---\n",
            "URL 1: green BAY\tMCCORMICK ASSISTED LIVING\n",
            "URL 2: GREEN BAY\tMCCORMICK ASSISTED LIVINGIIIII\n",
            "Similarity Score: 0.9090909090909091\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "def find_duplicates(dataset, threshold):\n",
        "    duplicates = []\n",
        "\n",
        "    for i in range(len(dataset)):\n",
        "        row1 = dataset[i]\n",
        "        if row1:\n",
        "            sentence1 = row1[-1].strip()\n",
        "            if sentence1:\n",
        "                for j in range(i + 1, len(dataset)):\n",
        "                    row2 = dataset[j]\n",
        "                    if row2:\n",
        "                        sentence2 = row2[-1].strip()\n",
        "                        if sentence2:\n",
        "                            similarity = SequenceMatcher(None, sentence1.lower(), sentence2.lower()).ratio()\n",
        "                            if similarity >= threshold:\n",
        "                                duplicates.append((row1, row2, similarity))\n",
        "\n",
        "    return duplicates\n",
        "\n",
        "# Read the dataset from the CSV file\n",
        "dataset_filename = \"/content/state_city.csv\"\n",
        "\n",
        "dataset = []\n",
        "\n",
        "with open(dataset_filename, \"r\") as csvfile:\n",
        "    reader = csv.reader(csvfile)\n",
        "    for row in reader:\n",
        "        dataset.append(row)\n",
        "\n",
        "threshold = 0.9  # Adjust the threshold as needed\n",
        "\n",
        "duplicates = find_duplicates(dataset, threshold)\n",
        "num_duplicates = len(duplicates)\n",
        "\n",
        "print(\"Number of duplicates:\", num_duplicates)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "b6n2G-lIZArK",
        "outputId": "8d8f0ec1-decf-4fa1-d28f-15df24c96eac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-0eb9d96f4dcb>\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.9\u001b[0m  \u001b[0;31m# Adjust the threshold as needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mduplicates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0mnum_duplicates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mduplicates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-0eb9d96f4dcb>\u001b[0m in \u001b[0;36mfind_duplicates\u001b[0;34m(dataset, threshold)\u001b[0m\n\u001b[1;32m     15\u001b[0m                         \u001b[0msentence2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0msentence2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                             \u001b[0msimilarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequenceMatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mratio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0msimilarity\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                                 \u001b[0mduplicates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/difflib.py\u001b[0m in \u001b[0;36mratio\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    617\u001b[0m         \"\"\"\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m         \u001b[0mmatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtriple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtriple\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_matching_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_calculate_ratio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/difflib.py\u001b[0m in \u001b[0;36mget_matching_blocks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    482\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mk1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m                     \u001b[0mnon_adjacent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m                 \u001b[0mi1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mk1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             \u001b[0mnon_adjacent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "def find_duplicates(dataset, threshold):\n",
        "    duplicates = []\n",
        "\n",
        "    for i in range(len(dataset)):\n",
        "        row1 = dataset[i]\n",
        "        if row1:\n",
        "            sentence1 = row1[-1].strip()\n",
        "            if sentence1:\n",
        "                for j in range(i + 1, len(dataset)):\n",
        "                    row2 = dataset[j]\n",
        "                    if row2:\n",
        "                        sentence2 = row2[-1].strip()\n",
        "                        if sentence2:\n",
        "                            similarity = SequenceMatcher(None, sentence1.lower(), sentence2.lower()).ratio()\n",
        "                            if similarity >= threshold:\n",
        "                                duplicates.append((row1, row2, similarity))\n",
        "\n",
        "    return duplicates\n",
        "\n",
        "# Read the dataset from the CSV file\n",
        "dataset_filename = \"/content/state_city.csv\"\n",
        "\n",
        "dataset = []\n",
        "\n",
        "with open(dataset_filename, \"r\") as csvfile:\n",
        "    reader = csv.reader(csvfile)\n",
        "    for row in reader:\n",
        "        dataset.append(row)\n",
        "\n",
        "threshold = 0.9  # Adjust the threshold as needed\n",
        "\n",
        "duplicates = find_duplicates(dataset, threshold)\n",
        "num_duplicates = len(duplicates)\n",
        "\n",
        "print(\"Number of duplicates:\", num_duplicates)\n",
        "\n",
        "# Save duplicates to a new CSV file\n",
        "output_filename = \"/content/duplicate_pairs.csv\"\n",
        "\n",
        "with open(output_filename, \"w\", newline=\"\") as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow([\"Duplicate 1\", \"Duplicate 2\", \"Similarity Ratio\"])\n",
        "    for pair in duplicates:\n",
        "        writer.writerow([pair[0][-1], pair[1][-1], pair[2]])\n",
        "\n",
        "print(\"Duplicate pairs saved to:\", output_filename)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qT9Qonu9aC-U",
        "outputId": "e21a995e-1d16-4e58-8bab-aa6051a5eba8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of duplicates: 914\n",
            "Duplicate pairs saved to: /content/duplicate_pairs.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "def find_duplicates(dataset, threshold):\n",
        "    duplicates = []\n",
        "\n",
        "    for i in range(len(dataset)):\n",
        "        row1 = dataset[i]\n",
        "        if row1:\n",
        "            sentence1 = row1[-1].strip()\n",
        "            if sentence1:\n",
        "                for j in range(i + 1, len(dataset)):\n",
        "                    row2 = dataset[j]\n",
        "                    if row2:\n",
        "                        sentence2 = row2[-1].strip()\n",
        "                        if sentence2:\n",
        "                            similarity = SequenceMatcher(None, sentence1.lower(), sentence2.lower()).ratio()\n",
        "                            if similarity >= threshold:\n",
        "                                duplicates.append((row1, row2, similarity))\n",
        "\n",
        "    return duplicates\n",
        "\n",
        "# Read the dataset from the CSV file\n",
        "dataset_filename = \"/content/state_city.csv\"\n",
        "\n",
        "dataset = []\n",
        "\n",
        "with open(dataset_filename, \"r\") as csvfile:\n",
        "    reader = csv.reader(csvfile)\n",
        "    for row in reader:\n",
        "        dataset.append(row)\n",
        "\n",
        "threshold = 0.9  # Adjust the threshold as needed\n",
        "\n",
        "duplicates = find_duplicates(dataset, threshold)\n",
        "num_duplicates = len(duplicates)\n",
        "\n",
        "print(\"Number of duplicates:\", num_duplicates)\n",
        "\n",
        "# Save duplicates to a new CSV file\n",
        "output_filename = \"/content/duplicate_pairs.csv\"\n",
        "\n",
        "# Use the same format as the input file\n",
        "header = None if len(dataset[0]) != 3 else dataset[0]  # Assuming each row has 3 columns\n",
        "\n",
        "with open(output_filename, \"w\", newline=\"\") as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    if header:\n",
        "        writer.writerow(header)\n",
        "    for pair in duplicates:\n",
        "        writer.writerow(pair[0])\n",
        "        writer.writerow(pair[1])\n",
        "\n",
        "print(\"Duplicate pairs saved to:\", output_filename)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31mDmr5FVEjG",
        "outputId": "aaa2df66-1913-4265-e04e-4cac1610898c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of duplicates: 914\n",
            "Duplicate pairs saved to: /content/duplicate_pairs.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "def find_duplicates(urls, threshold):\n",
        "    duplicates = []\n",
        "\n",
        "    for i in range(len(urls)):\n",
        "        url1 = urls[i]\n",
        "        if url1:\n",
        "            url1 = url1.strip()\n",
        "            if url1:\n",
        "                for j in range(i + 1, len(urls)):\n",
        "                    url2 = urls[j]\n",
        "                    if url2:\n",
        "                        url2 = url2.strip()\n",
        "                        if url2:\n",
        "                            similarity = SequenceMatcher(None, url1.lower(), url2.lower()).ratio()\n",
        "                            if similarity >= threshold:\n",
        "                                duplicates.append((url1, url2, similarity))\n",
        "                                break  # Skip checking further duplicates of url1\n",
        "\n",
        "    return duplicates\n",
        "\n",
        "urls = [\n",
        "    \"RIVER FALLS\\tREM WISCONSIN III INC GLENMEADOW\",\n",
        "    \"GREEN BAY\\tMCCORMICK ASSISTED LIVING\",\n",
        "    \"green BAY\\tMCCORMICK ASSISTED LIVING\",\n",
        "    \"GREEN BAY\\tMCCORMICK ASSISTED IVINGIIIII\",\n",
        "    \"GREEN BAY\\tMCCORMICK ASSISTED lIVINGIIIII\",\n",
        "    \"rIVER FALLS\\tREM WISCONSIN III INC GLENMEADOW\",\n",
        "    \"riVER FALLS\\tREM WISCONSIN III INC GLENMEADOW\",\n",
        "]\n",
        "\n",
        "threshold = 0.9  # Adjust the threshold as needed\n",
        "\n",
        "duplicates = find_duplicates(urls, threshold)\n",
        "num_duplicates = len(duplicates)\n",
        "\n",
        "print(\"Number of duplicates:\", num_duplicates)\n",
        "\n",
        "# Save duplicates to a new CSV file\n",
        "output_filename = \"duplicate_urls.csv\"\n",
        "\n",
        "with open(output_filename, \"w\", newline=\"\") as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow([\"Duplicate 1\", \"Duplicate 2\", \"Similarity Ratio\"])\n",
        "    for pair in duplicates:\n",
        "        writer.writerow([pair[0], pair[1], pair[2]])\n",
        "\n",
        "print(\"Duplicate URLs saved to:\", output_filename)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FR3L9Rsqwr2a",
        "outputId": "928f70c7-4cd6-420c-e328-7e18bab40100"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of duplicates: 5\n",
            "Duplicate URLs saved to: duplicate_urls.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "def find_duplicates(urls, threshold):\n",
        "    duplicates = []\n",
        "\n",
        "    for i in range(len(urls)):\n",
        "        url1 = urls[i]\n",
        "        if url1:\n",
        "            url1 = url1.strip()\n",
        "            if url1:\n",
        "                for j in range(i + 1, len(urls)):\n",
        "                    url2 = urls[j]\n",
        "                    if url2:\n",
        "                        url2 = url2.strip()\n",
        "                        if url2:\n",
        "                            similarity = SequenceMatcher(None, url1.lower(), url2.lower()).ratio()\n",
        "                            if similarity >= threshold:\n",
        "                                pair = (url1, url2, similarity)\n",
        "                                if pair not in duplicates and (pair[1], pair[0], pair[2]) not in duplicates:\n",
        "                                    duplicates.append(pair)\n",
        "\n",
        "    return duplicates\n",
        "\n",
        "urls = [\n",
        "    \"RIVER FALLS\\tREM WISCONSIN III INC GLENMEADOW\",\n",
        "    \"GREEN BAY\\tMCCORMICK ASSISTED LIVING\",\n",
        "    \"green BAY\\tMCCORMICK ASSISTED LIVING\",\n",
        "    \"GREEN BAY\\tMCCORMICK ASSISTED IVINGIIIII\",\n",
        "    \"GREEN BAY\\tMCCORMICK ASSISTED lIVINGIIIII\",\n",
        "    \"rIVER FALLS\\tREM WISCONSIN III INC GLENMEADOW\",\n",
        "    \"riVER FALLS\\tREM WISCONSIN III INC GLENMEADOW\",\n",
        "]\n",
        "\n",
        "threshold = 0.9  # Adjust the threshold as needed\n",
        "\n",
        "duplicates = find_duplicates(urls, threshold)\n",
        "num_duplicates = len(duplicates)\n",
        "\n",
        "print(\"Number of duplicates:\", num_duplicates)\n",
        "\n",
        "# Save duplicates to a new CSV file\n",
        "output_filename = \"duplicate_urls.csv\"\n",
        "\n",
        "with open(output_filename, \"w\", newline=\"\") as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow([\"Duplicate 1\", \"Duplicate 2\", \"Similarity Ratio\"])\n",
        "    for pair in duplicates:\n",
        "        writer.writerow([pair[0], pair[1], pair[2]])\n",
        "\n",
        "print(\"Duplicate URLs saved to:\", output_filename)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_e2_lZGVxjlp",
        "outputId": "9961ce15-f126-49fb-dbf3-0f6947fbf586"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of duplicates: 9\n",
            "Duplicate URLs saved to: duplicate_urls.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "def find_duplicates(urls, threshold):\n",
        "    duplicates = []\n",
        "\n",
        "    for i in range(len(urls)):\n",
        "        url1 = urls[i]\n",
        "        if url1:\n",
        "            url1 = url1.strip()\n",
        "            if url1:\n",
        "                for j in range(i + 1, len(urls)):\n",
        "                    url2 = urls[j]\n",
        "                    if url2:\n",
        "                        url2 = url2.strip()\n",
        "                        if url2:\n",
        "                            similarity = SequenceMatcher(None, url1.lower(), url2.lower()).ratio()\n",
        "                            if similarity >= threshold:\n",
        "                                pair = (url1, url2, similarity)\n",
        "                                if pair not in duplicates:\n",
        "                                    duplicates.append(pair)\n",
        "\n",
        "    return duplicates\n",
        "\n",
        "urls = [\n",
        "    \"RIVER FALLS\\tREM WISCONSIN III INC GLENMEADOW\",\n",
        "    \"GREEN BAY\\tMCCORMICK ASSISTED LIVING\",\n",
        "    \"green BAY\\tMCCORMICK ASSISTED LIVING\",\n",
        "    \"GREEN BAY\\tMCCORMICK ASSISTED IVINGIIIII\",\n",
        "    \"GREEN BAY\\tMCCORMICK ASSISTED lIVINGIIIII\",\n",
        "    \"rIVER FALLS\\tREM WISCONSIN III INC GLENMEADOW\",\n",
        "    \"riVER FALLS\\tREM WISCONSIN III INC GLENMEADOW\",\n",
        "]\n",
        "\n",
        "threshold = 0.9  # Adjust the threshold as needed\n",
        "\n",
        "duplicates = find_duplicates(urls, threshold)\n",
        "num_duplicates = len(duplicates)\n",
        "\n",
        "print(\"Number of duplicates:\", num_duplicates)\n",
        "\n",
        "# Save duplicates to a new CSV file\n",
        "output_filename = \"duplicate_urls.csv\"\n",
        "\n",
        "with open(output_filename, \"w\", newline=\"\") as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow([\"Duplicate 1\", \"Duplicate 2\", \"Similarity Ratio\"])\n",
        "    for pair in duplicates:\n",
        "        writer.writerow([pair[0], pair[1], pair[2]])\n",
        "\n",
        "print(\"Duplicate URLs saved to:\", output_filename)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjoXM4Ooyuie",
        "outputId": "61d5c44c-aae0-4b0f-d8f4-fbe5c6f36225"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of duplicates: 9\n",
            "Duplicate URLs saved to: duplicate_urls.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "def find_duplicates(urls, threshold):\n",
        "    duplicates = set()\n",
        "\n",
        "    for i in range(len(urls)):\n",
        "        url1 = urls[i]\n",
        "        if url1:\n",
        "            url1 = url1.strip()\n",
        "            if url1:\n",
        "                for j in range(i + 1, len(urls)):\n",
        "                    url2 = urls[j]\n",
        "                    if url2:\n",
        "                        url2 = url2.strip()\n",
        "                        if url2:\n",
        "                            similarity = SequenceMatcher(None, url1.lower(), url2.lower()).ratio()\n",
        "                            if similarity >= threshold:\n",
        "                                pair = (url1, url2, similarity)\n",
        "                                duplicates.add(pair)\n",
        "\n",
        "    return duplicates\n",
        "\n",
        "urls = [\n",
        "    \"RIVER FALLS\\tREM WISCONSIN III INC GLENMEADOW\",\n",
        "    \"GREEN BAY\\tMCCORMICK ASSISTED LIVING\",\n",
        "    \"green BAY\\tMCCORMICK ASSISTED LIVING\",\n",
        "    \"GREEN BAY\\tMCCORMICK ASSISTED IVINGIIIII\",\n",
        "    \"GREEN BAY\\tMCCORMICK ASSISTED lIVINGIIIII\",\n",
        "    \"rIVER FALLS\\tREM WISCONSIN III INC GLENMEADOW\",\n",
        "    \"riVER FALLS\\tREM WISCONSIN III INC GLENMEADOW\",\n",
        "]\n",
        "\n",
        "threshold = 0.9  # Adjust the threshold as needed\n",
        "\n",
        "duplicates = find_duplicates(urls, threshold)\n",
        "num_duplicates = len(duplicates)\n",
        "\n",
        "print(\"Number of duplicates:\", num_duplicates)\n",
        "\n",
        "# Save duplicates to a new CSV file\n",
        "output_filename = \"duplicate_urls.csv\"\n",
        "\n",
        "with open(output_filename, \"w\", newline=\"\") as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow([\"Duplicate 1\", \"Duplicate 2\", \"Similarity Ratio\"])\n",
        "    for pair in duplicates:\n",
        "        writer.writerow([pair[0], pair[1], pair[2]])\n",
        "\n",
        "print(\"Duplicate URLs saved to:\", output_filename)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vb4TKxc10Aow",
        "outputId": "12ec43db-9323-47dc-945a-66d4b4f6c853"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of duplicates: 9\n",
            "Duplicate URLs saved to: duplicate_urls.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trying set"
      ],
      "metadata": {
        "id": "BAdfMUU57cKr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import difflib\n",
        "\n",
        "urls = [\n",
        "    \"RIVER FALLS\\tREM WISCONSIN III INC GLENMEADOW\",\n",
        "    \"GREEN BAY\\tMCCORMICK ASSISTED LIVING\",\n",
        "    \"green BAY\\tMCCORMICK ASSISTED LIVING\",\n",
        "    \"GREEN BAY\\tMCCORMICK ASSISTED IVINGIIIII\",\n",
        "    \"GREEN BAY\\tMCCORMICK ASSISTED lIVINGIIIII\",\n",
        "    \"rIVER FALLS\\tREM WISCONSIN III INC GLENMEADOW\",\n",
        "    \"riVER FALLS\\tREM WISCONSIN III INC GLENMEADOW\",\n",
        "]\n",
        "\n",
        "duplicates = set()\n",
        "for i in range(len(urls)):\n",
        "    for j in range(i + 1, len(urls)):\n",
        "        similarity_ratio = difflib.SequenceMatcher(None, urls[i], urls[j]).ratio()\n",
        "        if similarity_ratio >= 0.9:\n",
        "            pair = (urls[i], urls[j])\n",
        "            duplicates.add(pair)\n",
        "\n",
        "# Print the unique duplicates\n",
        "for duplicate in duplicates:\n",
        "    print(duplicate)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1UWSnI40zLH",
        "outputId": "59526687-4305-4320-f1ac-583a1d086836"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('GREEN BAY\\tMCCORMICK ASSISTED LIVING', 'GREEN BAY\\tMCCORMICK ASSISTED lIVINGIIIII')\n",
            "('RIVER FALLS\\tREM WISCONSIN III INC GLENMEADOW', 'riVER FALLS\\tREM WISCONSIN III INC GLENMEADOW')\n",
            "('RIVER FALLS\\tREM WISCONSIN III INC GLENMEADOW', 'rIVER FALLS\\tREM WISCONSIN III INC GLENMEADOW')\n",
            "('GREEN BAY\\tMCCORMICK ASSISTED IVINGIIIII', 'GREEN BAY\\tMCCORMICK ASSISTED lIVINGIIIII')\n",
            "('rIVER FALLS\\tREM WISCONSIN III INC GLENMEADOW', 'riVER FALLS\\tREM WISCONSIN III INC GLENMEADOW')\n",
            "('GREEN BAY\\tMCCORMICK ASSISTED LIVING', 'GREEN BAY\\tMCCORMICK ASSISTED IVINGIIIII')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trying Map"
      ],
      "metadata": {
        "id": "e2wCpXiM7aZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import difflib\n",
        "\n",
        "urls = [\n",
        "    \"RIVER FALLS\\tREM WISCONSIN III INC GLENMEADOW\",\n",
        "    \"GREEN BAY\\tMCCORMICK ASSISTED LIVING\",\n",
        "    \"green BAY\\tMCCORMICK ASSISTED LIVING\",\n",
        "    \"GREEN BAY\\tMCCORMICK ASSISTED IVINGIIIII\",\n",
        "    \"GREEN BAY\\tMCCORMICK ASSISTED lIVINGIIIII\",\n",
        "    \"rIVER FALLS\\tREM WISCONSIN III INC GLENMEADOW\",\n",
        "    \"riVER FALLS\\tREM WISCONSIN III INC GLENMEADOW\",\n",
        "]\n",
        "\n",
        "duplicates = {}\n",
        "for i in range(len(urls)):\n",
        "    for j in range(i + 1, len(urls)):\n",
        "        similarity_ratio = difflib.SequenceMatcher(None, urls[i], urls[j]).ratio()\n",
        "        if similarity_ratio >= 0.9:\n",
        "            sentence1, sentence2 = urls[i], urls[j]\n",
        "            pair = (sentence1, sentence2)\n",
        "            duplicates[pair] = similarity_ratio\n",
        "\n",
        "# Print the unique duplicates\n",
        "for duplicate, similarity in duplicates.items():\n",
        "    print(duplicate[0], duplicate[1], similarity)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EaotpE_Y7PED",
        "outputId": "089b7322-096a-4188-9d9b-8f412d982dde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RIVER FALLS\tREM WISCONSIN III INC GLENMEADOW rIVER FALLS\tREM WISCONSIN III INC GLENMEADOW 0.9772727272727273\n",
            "RIVER FALLS\tREM WISCONSIN III INC GLENMEADOW riVER FALLS\tREM WISCONSIN III INC GLENMEADOW 0.9545454545454546\n",
            "GREEN BAY\tMCCORMICK ASSISTED LIVING GREEN BAY\tMCCORMICK ASSISTED IVINGIIIII 0.918918918918919\n",
            "GREEN BAY\tMCCORMICK ASSISTED LIVING GREEN BAY\tMCCORMICK ASSISTED lIVINGIIIII 0.9066666666666666\n",
            "GREEN BAY\tMCCORMICK ASSISTED IVINGIIIII GREEN BAY\tMCCORMICK ASSISTED lIVINGIIIII 0.9873417721518988\n",
            "rIVER FALLS\tREM WISCONSIN III INC GLENMEADOW riVER FALLS\tREM WISCONSIN III INC GLENMEADOW 0.9772727272727273\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCqg5Y4777LD",
        "outputId": "bc47a04b-dc27-426f-9507-239c47b68a44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GREEN BAY\tMCCORMICK ASSISTED LIVING GREEN BAY\tMCCORMICK ASSISTED lIVINGIIIII\n",
            "RIVER FALLS\tREM WISCONSIN III INC GLENMEADOW riVER FALLS\tREM WISCONSIN III INC GLENMEADOW\n",
            "GREEN BAY\tMCCORMICK ASSISTED IVINGIIIII GREEN BAY\tMCCORMICK ASSISTED LIVING\n",
            "RIVER FALLS\tREM WISCONSIN III INC GLENMEADOW rIVER FALLS\tREM WISCONSIN III INC GLENMEADOW\n",
            "GREEN BAY\tMCCORMICK ASSISTED IVINGIIIII GREEN BAY\tMCCORMICK ASSISTED lIVINGIIIII\n",
            "rIVER FALLS\tREM WISCONSIN III INC GLENMEADOW riVER FALLS\tREM WISCONSIN III INC GLENMEADOW\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "binary search tree (BST)"
      ],
      "metadata": {
        "id": "71cFEkh28Pqt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Node:\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "        self.children = {}\n",
        "\n",
        "def insert(node, pair):\n",
        "    if pair[0] not in node.children:\n",
        "        node.children[pair[0]] = Node(pair[0])\n",
        "    if pair[1] not in node.children:\n",
        "        node.children[pair[1]] = Node(pair[1])\n",
        "\n",
        "    return node.children[pair[0]], node.children[pair[1]]\n",
        "\n",
        "def print_duplicates(node, prefix=\"\"):\n",
        "    if len(node.children) > 1:\n",
        "        for child in node.children.values():\n",
        "            if child.data != node.data:\n",
        "                print(f\"{prefix}{node.data}\\t{child.data}\")\n",
        "    for child in node.children.values():\n",
        "        print_duplicates(child, prefix + \"\\t\")\n",
        "\n",
        "# Create the root node of the tree\n",
        "root = Node(None)\n",
        "\n",
        "# List of URLs\n",
        "urls = [\n",
        "    \"GREEN BAY\\tMCCORMICK ASSISTED IVINGIIIII\",\n",
        "    \"GREEN BAY\\tMCCORMICK ASSISTED LIVING\",\n",
        "    \"GREEN BAY\\tMCCORMICK ASSISTED IVINGIIIII\",\n",
        "    \"GREEN BAY\\tMCCORMICK ASSISTED lIVINGIIIII\",\n",
        "    \"RIVER FALLS\\tREM WISCONSIN III INC GLENMEADOW\",\n",
        "    \"rIVER FALLS\\tREM WISCONSIN III INC GLENMEADOW\",\n",
        "    \"riVER FALLS\\tREM WISCONSIN III INC GLENMEADOW\"\n",
        "]\n",
        "\n",
        "# Insert the URL pairs into the tree\n",
        "for url in urls:\n",
        "    pair = tuple(url.split(\"\\t\"))\n",
        "    current_node = root\n",
        "    for word in pair:\n",
        "        current_node, current_node_child = insert(current_node, pair)\n",
        "        current_node = current_node_child\n",
        "\n",
        "# Print the unique duplicate pairs\n",
        "print_duplicates(root)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1T3scS88OjT",
        "outputId": "49cc8f7c-b14e-4634-e09a-863e981e2759"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\tGREEN BAY\n",
            "None\tMCCORMICK ASSISTED IVINGIIIII\n",
            "None\tMCCORMICK ASSISTED LIVING\n",
            "None\tMCCORMICK ASSISTED lIVINGIIIII\n",
            "None\tRIVER FALLS\n",
            "None\tREM WISCONSIN III INC GLENMEADOW\n",
            "None\trIVER FALLS\n",
            "None\triVER FALLS\n",
            "\tMCCORMICK ASSISTED IVINGIIIII\tGREEN BAY\n",
            "\tMCCORMICK ASSISTED LIVING\tGREEN BAY\n",
            "\tMCCORMICK ASSISTED lIVINGIIIII\tGREEN BAY\n",
            "\tREM WISCONSIN III INC GLENMEADOW\tRIVER FALLS\n",
            "\tREM WISCONSIN III INC GLENMEADOW\trIVER FALLS\n",
            "\tREM WISCONSIN III INC GLENMEADOW\triVER FALLS\n"
          ]
        }
      ]
    }
  ]
}